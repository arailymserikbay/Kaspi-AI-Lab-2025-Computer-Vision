{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image classification Using VGG-16\n",
        "Dataset - CIFAR10"
      ],
      "metadata": {
        "id": "wDWLTajJU6Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lHAvHrEYU8_M"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. load and tranfrom dataset"
      ],
      "metadata": {
        "id": "9f2v2L4wVa0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "z8Ju5fLqVV87"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "nic3RH7XVxiH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "6L1XtBx9V_ES"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. define the vgg16 model"
      ],
      "metadata": {
        "id": "N71KbxfsWIFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = torchvision.models.vgg16(pretrained=False)\n",
        "\n",
        "print(vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3th5updWDNw",
        "outputId": "79c68dfd-6b19-4bb9-db55-efba18f10f69"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#modify the classifier\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "print(num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-UpGVTpYGKV",
        "outputId": "f09a6b82-992c-4194-d1dc-107e60401a86"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(vgg16.classifier.children())[:-1]\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxfi--wYYlbE",
        "outputId": "3478f709-3c9c-48a4-ec44-a619066ee916"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.extend([nn.Linear(num_features, 10)])\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frndQEXDYs0j",
        "outputId": "5f6d3916-4c92-4eae-cf70-58f2328d2006"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=10, bias=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier = nn.Sequential(*features)\n",
        "print(vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75LnyMNuY06i",
        "outputId": "127edfbe-5801-48e9-cfcc-0da5b747d3b7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur-QrV5fY4AC",
        "outputId": "2bb30445-8a65-4e27-aad2-16fdafd7bb9a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = vgg16.to(device)"
      ],
      "metadata": {
        "id": "MBZJzcbCahMv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. define loss function and optimizer"
      ],
      "metadata": {
        "id": "gwNvLJwicVfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "ZdYTvGtBcNEp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. train the model"
      ],
      "metadata": {
        "id": "OzXdQt32cvZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "# Initialize lists to store loss and accuracy of each epoch\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0  # to track the number of correct predictions\n",
        "    total = 0  # to track the total number of predictions\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = vgg16(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    losses.append(epoch_loss)  # Append the average loss for this epoch to the list\n",
        "    accuracies.append(epoch_accuracy)  # Append the accuracy for this epoch to the list\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}, Accuracy: {epoch_accuracy}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29pxZiNQcNCj",
        "outputId": "80123500-0a47-46b8-f76d-20270acb31a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.7962326902803212, Accuracy: 34.084%\n",
            "Epoch 2/10, Loss: 1.3775401706887755, Accuracy: 49.98%\n",
            "Epoch 3/10, Loss: 1.1460358583995798, Accuracy: 58.778%\n",
            "Epoch 4/10, Loss: 0.9565046871997421, Accuracy: 66.158%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ytkfhj06cNAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. save the model"
      ],
      "metadata": {
        "id": "e9mOf55-eHva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vgg16.state_dict(), 'vgg16_cifar10_without_transfer_learning.pth')"
      ],
      "metadata": {
        "id": "IHEqveVUd90b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. plot training loss and accuracy"
      ],
      "metadata": {
        "id": "hshupaRxeGJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `losses` and `accuracies` are lists containing loss and accuracy values for each epoch\n",
        "\n",
        "# Set up a figure with two subplots\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot for training loss\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
        "plt.plot(losses, label='Training Loss')\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot for training accuracy\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
        "plt.plot(accuracies, label='Training Accuracy')\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_suCTSp6d9yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. confusion matrix"
      ],
      "metadata": {
        "id": "1AnPC4r-eSYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions and true labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg16(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(trainset.classes))\n",
        "plt.xticks(tick_marks, trainset.classes, rotation=45)\n",
        "plt.yticks(tick_marks, trainset.classes)\n",
        "\n",
        "# Loop over data to plot text\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j],\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yv9pij7od9tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. load the model"
      ],
      "metadata": {
        "id": "v-EjwnhtgqO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.vgg16()  # Initialize the model\n",
        "# model.load_state_dict(torch.load('./vgg16_cifar10_without_transferlearning.pth'))\n",
        "# model = model.to(device)\n",
        "\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "model = models.vgg16(pretrained=False)  # Initialize VGG16 without pretrained weights\n",
        "\n",
        "# Modify the classifier to match the saved model\n",
        "num_features = model.classifier[6].in_features\n",
        "features = list(model.classifier.children())[:-1]  # Remove last layer\n",
        "features.extend([nn.Linear(num_features, 10)])  # Adapt to your dataset, CIFAR10 has 10 classes\n",
        "model.classifier = nn.Sequential(*features)\n",
        "\n",
        "# Load the state dict (model weights)\n",
        "model.load_state_dict(torch.load('./vgg16_cifar10_without_transferlearning.pth'))\n",
        "\n",
        "# Move the model to the appropriate device (GPU or CPU)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ZNSDtdTGgoiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. test the model"
      ],
      "metadata": {
        "id": "ICxZYnnFgtPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 1. Load the image\n",
        "image_path = 'test2.jpg'  # Change this to the path of your image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 2. Preprocess the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
        "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize it\n",
        "])\n",
        "input_image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# 3. Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 4. Make a prediction\n",
        "with torch.no_grad():\n",
        "    # Move the input and model to GPU for speed if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_image = input_image.to('cuda')\n",
        "        model.to('cuda')\n",
        "\n",
        "    output = model(input_image)\n",
        "\n",
        "# 5. Interpret the output\n",
        "_, predicted = torch.max(output, 1)  # Get the index of the highest log-probability\n",
        "\n",
        "# Get the class label (modify this part according to your dataset classes)\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "  # Replace with your own class labels\n",
        "predicted_class = class_labels[predicted.item()]\n",
        "\n",
        "print(\"Predicted Class: \", predicted_class)"
      ],
      "metadata": {
        "id": "2Fwr4YVWguXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 1. Load the image\n",
        "image_path = '/content/bird.jpeg'  # Change this to the path of your image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 2. Preprocess the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
        "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize it\n",
        "])\n",
        "input_image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# 3. Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 4. Make a prediction\n",
        "with torch.no_grad():\n",
        "    # Move the input and model to GPU for speed if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_image = input_image.to('cuda')\n",
        "        model.to('cuda')\n",
        "\n",
        "    output = model(input_image)\n",
        "\n",
        "# 5. Interpret the output\n",
        "_, predicted = torch.max(output, 1)  # Get the index of the highest log-probability\n",
        "\n",
        "# Get the class label (modify this part according to your dataset classes)\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "  # Replace with your own class labels\n",
        "predicted_class = class_labels[predicted.item()]\n",
        "\n",
        "print(\"Predicted Class: \", predicted_class)"
      ],
      "metadata": {
        "id": "BN4iPsexhnex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}