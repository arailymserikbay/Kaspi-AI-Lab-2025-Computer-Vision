{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JUMHEIxJh0F6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. load and transform dataset"
      ],
      "metadata": {
        "id": "MAHzC8GBiqlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
      ],
      "metadata": {
        "id": "t6TXWmqsim5_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l6XoylTjFcd",
        "outputId": "37807848-49da-43f0-9218-d8c2a5b0d96a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download=True,transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "SuiUSHnLjhUH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. define the vgg16 model"
      ],
      "metadata": {
        "id": "kOvAVEHbjmKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(pretrained=True)  # Loads the VGG16 model\n",
        "\n",
        "# Freeze model weights\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the classifier\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "features = list(vgg16.classifier.children())[:-1]  # Remove last layer\n",
        "features.extend([nn.Linear(num_features, len(trainset.classes))])  # Add our layer with 10 outputs\n",
        "vgg16.classifier = nn.Sequential(*features)  # Replace the model classifier\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(vgg16, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxFReckDnR5r",
        "outputId": "ca17a5ad-b7f6-45b3-b30e-81d2239462aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 119,586,826\n",
            "Non-trainable params: 14,714,688\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.77\n",
            "Params size (MB): 512.32\n",
            "Estimated Total Size (MB): 731.67\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. define loss fucntion and optimizer"
      ],
      "metadata": {
        "id": "jP4EpjNhoXwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "S8YiCQwcny7C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. train the model"
      ],
      "metadata": {
        "id": "i1Ow2IIpox7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "# Initialize lists to store loss and accuracy of each epoch\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0  # to track the number of correct predictions\n",
        "    total = 0  # to track the total number of predictions\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = vgg16(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    losses.append(epoch_loss)  # Append the average loss for this epoch to the list\n",
        "    accuracies.append(epoch_accuracy)  # Append the accuracy for this epoch to the list\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}, Accuracy: {epoch_accuracy}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xl76BIsSoxTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. save the model"
      ],
      "metadata": {
        "id": "bXe3zE5BpkZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vgg16.state_dict(), './vgg16_cifar10.pth')\n"
      ],
      "metadata": {
        "id": "Wr3l2853o2hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.plot training loss and accuracy"
      ],
      "metadata": {
        "id": "14KqWNeCpoEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `losses` and `accuracies` are lists containing loss and accuracy values for each epoch\n",
        "\n",
        "# Set up a figure with two subplots\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot for training loss\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
        "plt.plot(losses, label='Training Loss')\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot for training accuracy\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
        "plt.plot(accuracies, label='Training Accuracy')\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2qr1T5uqpm4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. confusion matrix"
      ],
      "metadata": {
        "id": "K4j9Xq0Fpsv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg16(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(trainset.classes))\n",
        "plt.xticks(tick_marks, trainset.classes, rotation=45)\n",
        "plt.yticks(tick_marks, trainset.classes)\n",
        "\n",
        "# Loop over data to plot text\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j],\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1uTqCiqRprrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. load the model"
      ],
      "metadata": {
        "id": "eepP39f8pycr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)  # Initialize VGG16 without pretrained weights\n",
        "\n",
        "# Modify the classifier to match the saved model\n",
        "num_features = model.classifier[6].in_features\n",
        "features = list(model.classifier.children())[:-1]  # Remove last layer\n",
        "features.extend([nn.Linear(num_features, 10)])  # Adapt to your dataset, CIFAR10 has 10 classes\n",
        "model.classifier = nn.Sequential(*features)\n",
        "\n",
        "# Load the state dict (model weights)\n",
        "model.load_state_dict(torch.load('./vgg16_cifar10.pth'))\n",
        "\n",
        "# Move the model to the appropriate device (GPU or CPU)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "EU1nS8LnpxJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. test the model"
      ],
      "metadata": {
        "id": "C6RlOsZPp1qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 1. Load the image\n",
        "image_path = '/content/bird.jpeg'  # Change this to the path of your image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 2. Preprocess the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
        "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize it\n",
        "])\n",
        "input_image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# 3. Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 4. Make a prediction\n",
        "with torch.no_grad():\n",
        "    # Move the input and model to GPU for speed if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_image = input_image.to('cuda')\n",
        "        model.to('cuda')\n",
        "\n",
        "    output = model(input_image)\n",
        "\n",
        "# 5. Interpret the output\n",
        "_, predicted = torch.max(output, 1)  # Get the index of the highest log-probability\n",
        "\n",
        "# Get the class label (modify this part according to your dataset classes)\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "  # Replace with your own class labels\n",
        "predicted_class = class_labels[predicted.item()]\n",
        "\n",
        "print(\"Predicted Class: \", predicted_class)"
      ],
      "metadata": {
        "id": "dCEQPWSip0kQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}